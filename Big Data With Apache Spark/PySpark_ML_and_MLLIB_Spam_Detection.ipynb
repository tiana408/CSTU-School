{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUdUZ4QUKyDP"
   },
   "source": [
    "<font size=5>\n",
    "\n",
    "Classification with PySpark ML\n",
    "\n",
    "Instruction, place data file \"SMSSpamCollection\" under data/SparkData folder before running the notebook\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igfx2jmsKyDb"
   },
   "source": [
    "<font size=5> This dataset does not have column name, but we will give the proper columns.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "3HWR8tIJKyDc",
    "outputId": "eba1e25d-ddcf-4629-9e2f-a47cf120b6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/hadoop/.local/lib/python3.9/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /home/hadoop/.local/lib/python3.9/site-packages\n",
      "sysconfig: /home/hadoop/.local/lib64/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/hadoop/.local/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/hadoop/.local/lib/python3.9/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hadoop/.local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /home/hadoop/.local/lib/python3.9/site-packages\n",
      "sysconfig: /home/hadoop/.local/lib64/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/27 22:19:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "#Read Data\n",
    "df = spark.read.csv(\"SMSSpamCollection (1).txt\", sep = \"\\t\", inferSchema=True, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iwy2rXSCKyDh"
   },
   "source": [
    "<font size=5> Show 3 lines to get an idea about the dataset,  _c0 looks like as a label, c1 looks feature </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VbJxGODMKyDi"
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1g8ru9ueKyDj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0 |_c1                                                                                                                                                        |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam|Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTBvu5ZqKyDk"
   },
   "source": [
    "<font size=5> Note: Spam is Spam, Han is OK.  Rename Column name _c0 as status, _c1 as feature  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6SI57Pj-KyDl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|status|message                                                                                                                                                    |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham   |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham   |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('_c0', 'status').withColumnRenamed('_c1', 'message')\n",
    "df.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMgMXibXKyDm"
   },
   "source": [
    "<font size=5>\n",
    "\n",
    "Encode status column to numeric: ham to 1.0 and spam to 0. All our fields need to be numeric for machine to learn, also rename the column status to label\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vqfJaxhoKyDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|1.0  |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|0.0  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('temp')\n",
    "df = spark.sql('select case status when \"ham\" then 1.0  else 0 end as label, message from temp')\n",
    "df.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZEeDyXnKyDo"
   },
   "source": [
    "<font size=5> 1 is OK, 0 is Junk </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FfkylwjKyDo"
   },
   "source": [
    "<font size=5>\n",
    "Tokenize the messages\n",
    "Tokenization is the process of taking text (such as a sentence) and breaking it into individual terms (usually words). Let’s tokenize the messages and create a list of words of each message.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "w3ywX6BuKyDp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |words                                                                                                                                                                                   |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |[go, until, jurong, point,, crazy.., available, only, in, bugis, n, great, world, la, e, buffet..., cine, there, got, amore, wat...]                                                    |\n",
      "|1.0  |Ok lar... Joking wif u oni...                                                                                                                              |[ok, lar..., joking, wif, u, oni...]                                                                                                                                                    |\n",
      "|0.0  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005., text, fa, to, 87121, to, receive, entry, question(std, txt, rate)t&c's, apply, 08452810075over18's]|\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import  Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "wordsData.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hZqePDqKyDq"
   },
   "source": [
    "<font size=5> CountVectorizer converts a collection of text documents to vectors of token counts.\n",
    "    \n",
    "See:\n",
    "https://spark.apache.org/docs/latest/ml-features#countvectorizer\n",
    "\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C3BiDdzCKyDq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|message                                                                                                                                                    |words                                                                                                                                                                                   |rawFeatures                                                                                                                                                                                               |\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |[go, until, jurong, point,, crazy.., available, only, in, bugis, n, great, world, la, e, buffet..., cine, there, got, amore, wat...]                                                    |(13587,[8,42,52,64,83,89,132,143,410,444,754,836,1550,1838,4257,6934,7375,8627,11267,12718],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                            |\n",
      "|1.0  |Ok lar... Joking wif u oni...                                                                                                                              |[ok, lar..., joking, wif, u, oni...]                                                                                                                                                    |(13587,[5,75,411,578,2735,4294],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                |\n",
      "|0.0  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005., text, fa, to, 87121, to, receive, entry, question(std, txt, rate)t&c's, apply, 08452810075over18's]|(13587,[0,3,8,20,55,68,82,167,246,295,417,579,593,760,992,1089,2149,2165,2514,3171,3436,3773,5075,5358],[3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer (inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "model = count.fit(wordsData)\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show(3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgTP8e-EKyDr"
   },
   "source": [
    "<font size=5>\n",
    "Apply Term frequency - inverse document frequency (TF-IDF)\n",
    "\n",
    "#IDF reduces the features that often appear in the corpus. When using text as a feature, this usually improves performance because the most common, and therefore less important, words are weighted down.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZCRjzRjQKyDs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |(13587,[8,42,52,64,83,89,132,143,410,444,754,836,1550,1838,4257,6934,7375,8627,11267,12718],[1.970607245960672,3.1126188501633374,3.2055125970560336,3.4442640460362344,3.822026551595063,3.805766030723283,4.207206988531722,4.32198250312415,5.293843086153116,5.407171771460119,5.917997395226109,6.141140946540319,6.680137447273006,6.8342881271002645,7.52743530766021,7.9329004157683745,7.9329004157683745,7.9329004157683745,7.9329004157683745,7.9329004157683745])                                                                                |\n",
      "|1.0  |(13587,[5,75,411,578,2735,4294],[2.016698353160939,3.5761915890787823,5.330210730323991,5.7356758384321544,7.239753235208429,7.52743530766021])                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|0.0  |(13587,[0,3,8,20,55,68,82,167,246,295,417,579,593,760,992,1089,2149,2165,2514,3171,3436,3773,5075,5358],[3.5949262673862785,1.5612885685365177,1.970607245960672,2.704469176684504,3.332742771603827,3.5634525633013525,3.6702205387270586,4.421354976937353,4.841857962410058,5.099687071712158,11.070010285940008,5.681608617161879,5.7356758384321544,5.917997395226109,6.228152323529949,6.323462503334274,7.016609683894219,7.016609683894219,15.05487061532042,7.239753235208429,7.239753235208429,7.52743530766021,7.52743530766021,7.52743530766021])|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import  IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.select(\"label\", \"features\").show(3,False)  #Only needed to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VPJjq_4UKyDt"
   },
   "outputs": [],
   "source": [
    "rescaledData.createOrReplaceTempView(\"rescaleData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "l4e81w2pKyDt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(13587,[8,42,52,6...|\n",
      "|(13587,[5,75,411,...|\n",
      "|(13587,[0,3,8,20,...|\n",
      "|(13587,[5,22,60,1...|\n",
      "|(13587,[0,1,66,87...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select features from rescaleData limit 5\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZjP3jjsKyDu"
   },
   "source": [
    "<font size=5>\n",
    "Randomly Split DataFrame into 80% Training (trainDF) and 20 Testing (testDF)\n",
    "    \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zFUZzLNmKyDv"
   },
   "outputs": [],
   "source": [
    "seed = 0  # random seed 0\n",
    "trainDF, testDF = rescaledData.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN0AISoUKyDv"
   },
   "source": [
    "<font size=5> counts of train and test DataFrame </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jArGi_NCKyDv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4424"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c9cvK_LvKyDv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FGWFSq9KyDw"
   },
   "source": [
    "<font size=5>\n",
    "Try different classifiers.\n",
    "\n",
    "Logistic regression classifier\n",
    "\n",
    "Logistic regression is a common method of predicting classification responses. A special case of a generalized linear model is the probability of predicting a result. In spark.ml, logistic regression can be used to predict binary results by binomial logistic regression, or it can be used to predict multiple types of results by using multiple logistic regression. Use the family parameter to choose between these two algorithms, or leave it unset and Spark will infer the correct variable.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nbzjbZI1KyDw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "lr = LogisticRegression(maxIter = 100)\n",
    "\n",
    "model_lr = lr.fit(trainDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bj_nzm09KyDw"
   },
   "outputs": [],
   "source": [
    "prediction_lr = model_lr.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "feN0PsmPKyDw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475499400198194"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_lr = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_lr.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qME_VHLeKyDx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9848942383213879"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_lr.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CzwZmZw4KyDx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852173913043478"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iD5K21WhKyDx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|   16|\n",
      "|  1.0|       1.0|  995|\n",
      "|  0.0|       0.0|  138|\n",
      "|  1.0|       0.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fit_lr = prediction_lr.select('label','prediction')\n",
    "train_fit_lr.groupBy('label','prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaZ7IaTqKyDy"
   },
   "source": [
    "<font size=5>\n",
    "Naive Bayes\n",
    "Naive Bayesian classifiers are a class of simple probability classifiers that apply strong (naive) independent assumptions between features based on Bayes' theorem. The spark.ml implementation currently supports polynomial naive Bayes and Bernoulli Naïve Bayes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SNCeDjX6KyDy"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes()\n",
    "Model_nb = nb.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "buCvnLMVKyDy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_nb = Model_nb.transform(testDF)\n",
    "predictions_nb.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pUM7Ssg9KyDz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949864392635477"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_nb = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_nb.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "S-NabdtnKyDz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9372189798267707"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_nb = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_nb.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "tRK0xQzOKyDz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321739130434783"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_nb = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_nb.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPcuH7qfKyD0"
   },
   "source": [
    "<font size=5>\n",
    "\n",
    "Now let's try Random Forest Classfication to see how it performs on the classification on the same data\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "X4K3hxRHKyD0"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JN9YSE2RKyD7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction',maxDepth=3)\n",
    "Model_rf = rf.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kFvytbc_KyD7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = Model_rf.transform(testDF)\n",
    "predictions_rf.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "r5zFBFFLKyD7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_rf = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_rf.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUF9nfPjKyD8"
   },
   "source": [
    "<font size=5>\n",
    "\n",
    "Given Area Under Curve is 0.5, we do not want to use this Random Forest Classification.  Area under Curve is between 0 to 1,\n",
    "the more close to 1 the better the classication is.\n",
    "\n",
    "We wil give up Random Forest on this classitication\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4nH52D4mKyD8"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Lrx5KuDlKyD8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model_gbt=gbt.fit(trainDF)\n",
    "predictions_gbt=model_gbt.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "4iGlOKM3KyD9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|             message|               words|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|2p per min to cal...|[2p, per, min, to...|(13587,[0,10,11,1...|(13587,[0,10,11,1...|[1.29041568799839...|[0.92961768434495...|       0.0|\n",
      "|  0.0|3 FREE TAROT TEXT...|[3, free, tarot, ...|(13587,[0,10,11,5...|(13587,[0,10,11,5...|[0.74897381707673...|[0.81726817357518...|       0.0|\n",
      "|  0.0|5 Free Top Polyph...|[5, free, top, po...|(13587,[0,3,15,34...|(13587,[0,3,15,34...|[1.70856338754911...|[0.96823552295241...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|(13587,[0,40,64,8...|[-0.5733911736343...|[0.24107729111878...|       1.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|(13587,[0,40,64,8...|[-0.5733911736343...|[0.24107729111878...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_gbt.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3xKCnd0gKyD9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8768254837531946"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_gbt = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_gbt.evaluate(predictions_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3LFxn_JlKyD9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519440759890753"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_gbt = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_gbt.evaluate(predictions_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WZGNsvvsKyD9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321739130434783"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_gbt = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_gbt.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JEfWLSwKyD-"
   },
   "source": [
    "<font size=5>\n",
    "\n",
    "Model performance from Gradient Boosting Tree is good.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xaXZm6B6KyD-"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tI3NFxccKyD-"
   },
   "outputs": [],
   "source": [
    "model_lsvc=lsvc.fit(trainDF)\n",
    "predictions_lsvc=model_lsvc.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LNBOfWcAKyD-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|             message|               words|         rawFeatures|            features|       rawPrediction|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|2p per min to cal...|[2p, per, min, to...|(13587,[0,10,11,1...|(13587,[0,10,11,1...|[4.75723786234723...|       0.0|\n",
      "|  0.0|3 FREE TAROT TEXT...|[3, free, tarot, ...|(13587,[0,10,11,5...|(13587,[0,10,11,5...|[4.00286362697667...|       0.0|\n",
      "|  0.0|5 Free Top Polyph...|[5, free, top, po...|(13587,[0,3,15,34...|(13587,[0,3,15,34...|[4.58169856745822...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|(13587,[0,40,64,8...|[3.82684320293181...|       0.0|\n",
      "|  0.0|500 New Mobiles f...|[500, new, mobile...|(13587,[0,40,64,8...|(13587,[0,40,64,8...|[3.82684320293181...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lsvc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "61WxluURKyD_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8768254837531946"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_lsvc = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_lsvc.evaluate(predictions_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "b9pgrqqpKyEA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519440759890753"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lsvc = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_lsvc.evaluate(predictions_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "q2Q9sIjmKyEA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9530434782608695"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lsvc = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lsvc.evaluate(predictions_gbt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "gzCNFPrLKyEA"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I167Z9-CKyEA"
   },
   "source": [
    "<font size=5>\n",
    "\n",
    "Model performance from Linear Support Vector Machine is good.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JglKSQ8NKyEB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
